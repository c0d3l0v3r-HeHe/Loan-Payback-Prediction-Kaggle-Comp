{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66e96c36",
   "metadata": {},
   "source": [
    "<div style=\"background: linear-gradient(135deg, #1e3c72 0%, #2a5298 100%); padding: 40px; border-radius: 15px; text-align: center; box-shadow: 0 4px 6px rgba(0,0,0,0.1);\">\n",
    "    <h1 style=\"color: #ffffff; font-size: 48px; margin: 0; text-shadow: 2px 2px 4px rgba(0,0,0,0.3);\">ğŸ¦ Loan Repayment Prediction</h1>\n",
    "    <p style=\"color: #e8f4f8; font-size: 22px; margin-top: 15px;\">Advanced Machine Learning with XGBoost & Grid Search CV</p>\n",
    "</div>\n",
    "\n",
    "<center>\n",
    "<img src=\"https://media.giphy.com/media/67ThRZlYBvibtdF9JH/giphy.gif\" width=\"400\">\n",
    "<br>\n",
    "<i style=\"font-size: 12px; color: #666;\">GIF via GIPHY</i>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2078075",
   "metadata": {},
   "source": [
    "<div style=\"border: 2px solid #1e3c72; background-color: #f0f7ff; padding: 15px; border-radius: 10px; margin: 20px 0;\">\n",
    "<h4 style=\"color: #1e3c72; margin-top: 0; font-size: 18px;\">ğŸ‘¨â€ğŸ’» Credits & Acknowledgments</h4>\n",
    "\n",
    "<p style=\"color: #2c3e50; font-size: 14px; line-height: 1.8;\">\n",
    "<b style=\"color: #1e3c72;\">Machine Learning Approach & Model Code:</b> Developed by <a href=\"https://github.com/c0d3l0v3r-HeHe\" target=\"_blank\" style=\"color: #0066cc; text-decoration: none; font-weight: bold;\">@c0d3l0v3r-HeHe</a><br>\n",
    "<b style=\"color: #1e3c72;\">Notebook Formatting & Design:</b> Enhanced with GitHub Copilot<br>\n",
    "<b style=\"color: #1e3c72;\">GIF Credit:</b> GIPHY<br><br>\n",
    "<b style=\"color: #1e3c72;\">ğŸ“‚ Original Repository:</b> <a href=\"https://github.com/c0d3l0v3r-HeHe/Loan-Payback-Prediction-Kaggle-Comp\" target=\"_blank\" style=\"color: #0066cc; text-decoration: none; font-weight: bold;\">Loan-Payback-Prediction-Kaggle-Comp</a><br>\n",
    "<b style=\"color: #1e3c72;\">ğŸ““ Original Notebook:</b> <code style=\"background-color: #e8f4f8; padding: 2px 6px; border-radius: 3px; color: #1e3c72;\">notebook_submission.ipynb</code> (without decorations)\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d604b2",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\" style=\"border-left: 5px solid #0066cc; background-color: #e7f3ff; color: #2c3e50;\">\n",
    "<h3 style=\"color: #0066cc; margin-top: 0;\">ğŸ“Œ Competition Overview</h3>\n",
    "\n",
    "<b>Objective:</b> Predict whether a loan will be paid back based on borrower characteristics and loan features.<br><br>\n",
    "\n",
    "<b>ğŸ¯ Evaluation Metric:</b> ROC-AUC (Area Under the Receiver Operating Characteristic Curve)<br>\n",
    "<b>ğŸ’¡ Approach:</b> XGBoost with Grid Search Cross-Validation for optimal hyperparameters<br>\n",
    "<b>âš¡ Hardware:</b> GPU-accelerated training for faster execution<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9d6e84",
   "metadata": {},
   "source": [
    "<h1 align=\"center\" style=\"color: #1e3c72; font-size: 48px;\">ğŸ¦ Loan Repayment Prediction using XGBoost</h1>\n",
    "\n",
    "<div align=\"center\">\n",
    "    <img src=\"https://img.shields.io/badge/Python-3.10+-3776ab.svg\" alt=\"Python\">\n",
    "    <img src=\"https://img.shields.io/badge/XGBoost-Latest-00a651.svg\" alt=\"XGBoost\">\n",
    "    <img src=\"https://img.shields.io/badge/ROC--AUC-Optimized-ff6b35.svg\" alt=\"ROC-AUC\">\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“‹ Overview\n",
    "\n",
    "This notebook presents a **complete end-to-end machine learning pipeline** for predicting loan repayment outcomes using XGBoost with optimized hyperparameters.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\" style=\"background-color: #e7f3ff; border-left: 5px solid #0066cc; color: #2c3e50;\">\n",
    "<b>ğŸ’¡ What makes this notebook special?</b><br>\n",
    "We used <b>Grid Search Cross-Validation</b> to find the optimal hyperparameters, ensuring the best possible model performance!\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "### <font color='#1e3c72'>ğŸ“š Table of Contents</font><a class='anchor' id='top'></a>\n",
    "\n",
    "1. [ğŸ“š Import Libraries](#section1)\n",
    "2. [ğŸ” Exploratory Data Analysis (EDA)](#section2)\n",
    "   - [Dataset Overview](#section2-1)\n",
    "   - [Categorical Features Analysis](#section2-2)\n",
    "   - [Key Observations](#section2-3)\n",
    "3. [ğŸ› ï¸ Feature Engineering & Preprocessing](#section3)\n",
    "   - [Custom Transformations](#section3-1)\n",
    "   - [Feature Type Identification](#section3-2)\n",
    "   - [Building Pipelines](#section3-3)\n",
    "4. [ğŸ“Š Data Splitting](#section4)\n",
    "5. [ğŸ¤– Model Training with XGBoost](#section5)\n",
    "   - [Hyperparameter Selection](#section5-1)\n",
    "   - [Model Training](#section5-2)\n",
    "6. [ğŸ“ˆ Model Evaluation](#section6)\n",
    "   - [Performance Metrics](#section6-1)\n",
    "   - [Feature Importance](#section6-2)\n",
    "7. [ğŸ’¾ Save Model](#section7)\n",
    "8. [ğŸ¯ Generate Predictions](#section8)\n",
    "9. [ğŸ‰ Summary](#section9)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8bf735",
   "metadata": {},
   "source": [
    "<a id='section1'></a>\n",
    "## ğŸ“š Import Required Libraries\n",
    "[Back to top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba717c04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… All libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Data manipulation and analysis ğŸ“Š\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Machine Learning libraries ğŸ¤–\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, classification_report\n",
    "\n",
    "# Utilities ğŸ› ï¸\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"âœ… All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7f9118",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id='section2'></a>\n",
    "## ğŸ” Exploratory Data Analysis (EDA)\n",
    "[Back to top](#top)\n",
    "\n",
    "<a id='section2-1'></a>\n",
    "### ğŸ“Š Dataset Overview\n",
    "\n",
    "Let's start by loading and understanding our training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b951592c",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/kaggle/input/loan-repayment-prediction/train.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Load the training dataset\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/kaggle/input/loan-repayment-prediction/train.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m60\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mğŸ“Š Dataset Shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda/envs/torch-gpu/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda/envs/torch-gpu/lib/python3.11/site-packages/pandas/io/parsers/readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda/envs/torch-gpu/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda/envs/torch-gpu/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda/envs/torch-gpu/lib/python3.11/site-packages/pandas/io/common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '/kaggle/input/loan-repayment-prediction/train.csv'"
     ]
    }
   ],
   "source": [
    "# Load the training dataset\n",
    "df = pd.read_csv(\"/kaggle/input/loan-repayment-prediction/train.csv\")\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(f\"ğŸ“Š Dataset Shape: {df.shape}\")\n",
    "print(f\"ğŸ“Š Number of samples: {df.shape[0]:,}\")\n",
    "print(f\"ğŸ“Š Number of features: {df.shape[1]}\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nğŸ” First 5 rows of the dataset:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8838879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data types and missing values\n",
    "print(\"ğŸ“‹ Dataset Information:\")\n",
    "print(\"=\"*60)\n",
    "df.info()\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900d61b1",
   "metadata": {},
   "source": [
    "<a id='section2-2'></a>\n",
    "### ğŸ“Š Analyzing Categorical Features\n",
    "\n",
    "Let's examine the distribution of categorical variables to understand our feature space better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0001367",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Education Level Distribution\n",
    "print(\"ğŸ“ Education Level Distribution:\")\n",
    "print(\"=\"*60)\n",
    "print(df[\"education_level\"].value_counts())\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b27bc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Employment Status Distribution\n",
    "print(\"ğŸ’¼ Employment Status Distribution:\")\n",
    "print(\"=\"*60)\n",
    "print(df[\"employment_status\"].value_counts())\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99118278",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loan Purpose Distribution\n",
    "print(\"ğŸ¯ Loan Purpose Distribution:\")\n",
    "print(\"=\"*60)\n",
    "print(df[\"loan_purpose\"].value_counts())\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc455d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grade/Subgrade Distribution\n",
    "print(\"ğŸ“ˆ Grade Subgrade Distribution:\")\n",
    "print(\"=\"*60)\n",
    "print(df[\"grade_subgrade\"].value_counts())\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nğŸ“Œ Total unique grade_subgrade values: {df['grade_subgrade'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d25782a",
   "metadata": {},
   "source": [
    "<a id='section2-3'></a>\n",
    "### ğŸ’¡ Key Observations from EDA\n",
    "\n",
    "<div class=\"alert alert-block alert-success\" style=\"background-color: #d4edda; border-left: 5px solid #28a745; color: #2c3e50;\">\n",
    "<b style=\"color: #28a745;\">âœ… Preprocessing Strategy:</b><br><br>\n",
    "\n",
    "Based on our analysis, here are the preprocessing decisions:\n",
    "\n",
    "<b>1. ID Column:</b> Will be removed as it's just an identifier<br>\n",
    "<b>2. Numerical Features:</b> Different scales â†’ Apply <b>StandardScaler</b> for normalization<br>\n",
    "<b>3. Categorical Features:</b>\n",
    "<ul>\n",
    "   <li><b>Marital Status:</b> Binary encoding (1 if married, 0 otherwise)</li>\n",
    "   <li><b>Education Level:</b> One-Hot Encoding (multiple categories)</li>\n",
    "   <li><b>Employment Status:</b> One-Hot Encoding (multiple categories)</li>\n",
    "   <li><b>Loan Purpose:</b> One-Hot Encoding (multiple categories)</li>\n",
    "   <li><b>Grade Subgrade:</b> Split into two features:\n",
    "     <ul>\n",
    "       <li><code>grade</code>: Letter grade (A, B, C, etc.)</li>\n",
    "       <li><code>sub_grade</code>: Numeric subgrade (1, 2, 3, etc.)</li>\n",
    "       <li>Both will be One-Hot encoded</li>\n",
    "     </ul>\n",
    "   </li>\n",
    "</ul>\n",
    "</div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d366686d",
   "metadata": {},
   "source": [
    "<a id='section3'></a>\n",
    "## ğŸ› ï¸ Feature Engineering & Preprocessing\n",
    "[Back to top](#top)\n",
    "\n",
    "<div class=\"alert alert-block alert-info\" style=\"background-color: #e7f3ff; border-left: 5px solid #0066cc; color: #2c3e50;\">\n",
    "<b style=\"color: #0066cc;\">ğŸ“š Learn More About Feature Engineering:</b><br>\n",
    "For a comprehensive guide on feature engineering techniques, check out this excellent article:<br>\n",
    "<a href=\"https://www.geeksforgeeks.org/machine-learning/what-is-feature-engineering/\" target=\"_blank\" style=\"color: #0066cc; font-weight: bold;\">What is Feature Engineering? - GeeksforGeeks</a><br>\n",
    "<i>Credit: nikhilbhoi9739</i>\n",
    "</div>\n",
    "\n",
    "<a id='section3-1'></a>\n",
    "### ğŸ”§ Custom Preprocessing Function\n",
    "\n",
    "We'll create a function to:\n",
    "- Convert marital status to binary\n",
    "- Split grade_subgrade into separate grade and sub_grade features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0edb4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to grade/subgrade division and marital Status \n",
    "def marital_grade(df:pd.DataFrame)->pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    df[\"marital_status\"] = (df[\"marital_status\"] == \"Married\").astype(int)\n",
    "    df[\"grade\"] = [g[0] for g in df[\"grade_subgrade\"]]\n",
    "    df[\"sub_grade\"] = [g[1] for g in df[\"grade_subgrade\"]]\n",
    "    df.drop(columns=[\"grade_subgrade\"], inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ded1247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the function : \n",
    "df = marital_grade(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2064c740",
   "metadata": {},
   "source": [
    "<a id='section3-2'></a>\n",
    "### \udd0d Identify Feature Types\n",
    "\n",
    "Separate numerical and categorical features for different preprocessing pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58667ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify numerical features\n",
    "NUM_FEATURES = df_transformed.select_dtypes(include=[\"int64\", \"float64\"]).columns.to_list()\n",
    "NUM_FEATURES.remove(\"loan_paid_back\")  # Target variable\n",
    "NUM_FEATURES.remove(\"id\")              # Identifier column\n",
    "\n",
    "# Identify categorical features\n",
    "CAT_FEATURES = df_transformed.select_dtypes(include=[\"object\"]).columns.to_list()\n",
    "\n",
    "print(f\"ğŸ“Š Numerical Features ({len(NUM_FEATURES)}): {NUM_FEATURES}\")\n",
    "print(f\"\\nğŸ“Š Categorical Features ({len(CAT_FEATURES)}): {CAT_FEATURES}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f3928d",
   "metadata": {},
   "source": [
    "<a id='section3-3'></a>\n",
    "### ğŸ—ï¸ Build Preprocessing Pipelines\n",
    "\n",
    "<div class=\"alert alert-block alert-info\" style=\"background-color: #e7f3ff; border-left: 5px solid #0066cc; color: #2c3e50;\">\n",
    "<b style=\"color: #0066cc;\">ğŸ”„ Pipeline Architecture:</b><br>\n",
    "We'll create separate pipelines for categorical and numerical features:<br>\n",
    "â€¢ <b>Categorical Pipeline:</b> One-Hot Encoding with unknown category handling<br>\n",
    "â€¢ <b>Numerical Pipeline:</b> Standard Scaling for normalization\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0843fa87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical preprocessing pipeline\n",
    "cat_pipeline = Pipeline([\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore', sparse_output=True))\n",
    "])\n",
    "\n",
    "# Numerical preprocessing pipeline\n",
    "num_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Combine both pipelines\n",
    "preprocessing_pipeline = ColumnTransformer([\n",
    "    ('cat', cat_pipeline, CAT_FEATURES),\n",
    "    ('num', num_pipeline, NUM_FEATURES)\n",
    "])\n",
    "\n",
    "print(\"âœ… Preprocessing pipelines created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d6a0d0",
   "metadata": {},
   "source": [
    "### âœ… Test Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5886c053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features and target\n",
    "X = df.drop(columns=['loan_paid_back', 'id'])\n",
    "y = df['loan_paid_back']\n",
    "\n",
    "# Apply feature engineering\n",
    "X_transformed = marital_grade(X)\n",
    "\n",
    "# Fit and transform the data\n",
    "X_preprocessed = preprocessing_pipeline.fit_transform(X_transformed)\n",
    "\n",
    "print(f\"âœ… Preprocessing complete!\")\n",
    "print(f\"ğŸ“Š Original shape: {X.shape}\")\n",
    "print(f\"ğŸ“Š Preprocessed shape: {X_preprocessed.shape}\")\n",
    "print(f\"ğŸ“Š Total features after encoding: {X_preprocessed.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0acddee",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id='section4'></a>\n",
    "## ğŸ“Š Data Splitting\n",
    "[Back to top](#top)\n",
    "\n",
    "Split the data into training, validation, and test sets with **stratification** to maintain class balance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70838e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First split: 80% train, 20% temp\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Second split: Split temp into validation and test (50-50)\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp\n",
    ")\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"ğŸ“Š Data Split Summary\".center(70))\n",
    "print(\"=\"*70)\n",
    "print(f\"   {'Dataset':<20} {'Samples':>15} {'Percentage':>15}\")\n",
    "print(\"-\"*70)\n",
    "print(f\"   {'Training set':<20} {X_train.shape[0]:>15,} {X_train.shape[0]/len(X)*100:>14.1f}%\")\n",
    "print(f\"   {'Validation set':<20} {X_val.shape[0]:>15,} {X_val.shape[0]/len(X)*100:>14.1f}%\")\n",
    "print(f\"   {'Test set':<20} {X_test.shape[0]:>15,} {X_test.shape[0]/len(X)*100:>14.1f}%\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c22be8",
   "metadata": {},
   "source": [
    "### ğŸ”„ Apply Preprocessing to All Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462eb3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_fn(df:pd.DataFrame)->pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    df = marital_grade(df)\n",
    "    df = preprocessing_pipeline.transform(df)\n",
    "    return df\n",
    "\n",
    "# Apply preprocessing to all splits\n",
    "print(\"ğŸ”„ Applying preprocessing to all data splits...\")\n",
    "print()\n",
    "\n",
    "X_train_prep = preprocess_fn(X_train)\n",
    "X_val_prep = preprocess_fn(X_val)\n",
    "X_test_prep = preprocess_fn(X_test)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"âœ… Preprocessing applied to all splits!\".center(70))\n",
    "print(\"=\"*70)\n",
    "print(f\"\\n{'Dataset':<20} {'Original Shape':>20} {'Preprocessed Shape':>25}\")\n",
    "print(\"-\"*70)\n",
    "print(f\"{'Train':<20} {str(X_train.shape):>20} {str(X_train_prep.shape):>25}\")\n",
    "print(f\"{'Validation':<20} {str(X_val.shape):>20} {str(X_val_prep.shape):>25}\")\n",
    "print(f\"{'Test':<20} {str(X_test.shape):>20} {str(X_test_prep.shape):>25}\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nâœ¨ Total features after encoding: {X_train_prep.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc0a273",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id='section5'></a>\n",
    "## ğŸ¤– Model Training with XGBoost\n",
    "[Back to top](#top)\n",
    "\n",
    "<a id='section5-1'></a>\n",
    "### ğŸ¯ Hyperparameter Selection\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\" style=\"background-color: #fff3cd; border-left: 5px solid #ff9800; color: #2c3e50;\">\n",
    "<b style=\"color: #ff9800;\">âš™ï¸ Grid Search Cross-Validation Process:</b><br><br>\n",
    "\n",
    "We performed <b>Grid Search Cross-Validation</b> to find the optimal hyperparameters. The search space included:\n",
    "\n",
    "```python\n",
    "param_grid = {\n",
    "    'n_estimators': [200, 500],\n",
    "    'max_depth': [4, 6, 8],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'subsample': [0.7, 0.9],\n",
    "    'colsample_bytree': [0.7, 0.9],\n",
    "    'reg_lambda': [1, 2],\n",
    "    'min_child_weight': [1, 3]\n",
    "}\n",
    "```\n",
    "\n",
    "ğŸ“Š <b>Search Configuration:</b>\n",
    "<ul>\n",
    "<li>3-fold Cross-Validation</li>\n",
    "<li>Optimization Metric: ROC-AUC</li>\n",
    "<li>Total combinations tested: 288</li>\n",
    "</ul>\n",
    "</div>\n",
    "\n",
    "After exhaustive search, the **best parameters** were identified and are used below.\n",
    "\n",
    "### ğŸ—ï¸ Building the Model\n",
    "\n",
    "We'll train an XGBoost classifier with the optimized hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99515ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DMatrix objects for efficient XGBoost training\n",
    "dtrain = xgb.DMatrix(X_train_prep, label=y_train)\n",
    "dval = xgb.DMatrix(X_val_prep, label=y_val)\n",
    "dtest = xgb.DMatrix(X_test_prep, label=y_test)\n",
    "\n",
    "print(\"âœ… DMatrix objects created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71981e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best hyperparameters from Grid Search CV\n",
    "# These parameters were obtained through extensive hyperparameter tuning\n",
    "params = {\n",
    "    \"objective\": \"binary:logistic\",      # Binary classification\n",
    "    \"eval_metric\": \"auc\",                # Optimize for ROC-AUC\n",
    "    \"tree_method\": \"hist\",               # Fast histogram-based algorithm\n",
    "    \"device\": \"cuda\",                    # GPU acceleration (change to 'cpu' if needed)\n",
    "    \n",
    "    # Optimized hyperparameters from Grid Search\n",
    "    \"max_depth\": 6,                      # Maximum tree depth\n",
    "    \"eta\": 0.05,                         # Learning rate\n",
    "    \"subsample\": 0.9,                    # Row sampling ratio\n",
    "    \"colsample_bytree\": 0.9,             # Column sampling ratio\n",
    "    \"reg_lambda\": 1,                     # L2 regularization\n",
    "    \"min_child_weight\": 1,               # Minimum sum of instance weight\n",
    "    \"seed\": 42                           # Random seed for reproducibility\n",
    "}\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"âš™ï¸  Model Hyperparameters Configuration\".center(70))\n",
    "print(\"=\"*70)\n",
    "print(f\"\\n{'Parameter':<30} {'Value':>20}\")\n",
    "print(\"-\"*70)\n",
    "for key, value in params.items():\n",
    "    print(f\"{key:<30} {str(value):>20}\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nâœ¨ These hyperparameters were selected via Grid Search CV!\")\n",
    "print(\"ğŸ¯ Optimization metric: ROC-AUC\")\n",
    "print(\"ğŸ”„ Cross-validation folds: 3\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2802e1e1",
   "metadata": {},
   "source": [
    "<a id='section5-2'></a>\n",
    "### ğŸš€ Training the Model\n",
    "\n",
    "We'll train the model with **early stopping** to prevent overfitting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6028e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up evaluation sets for monitoring\n",
    "evals = [(dtrain, \"train\"), (dval, \"val\")]\n",
    "\n",
    "# Train the model with early stopping\n",
    "print(\"ğŸš€ Training XGBoost model...\")\n",
    "print(\"=\"*70)\n",
    "print(\"â° This may take a few minutes depending on your hardware...\")\n",
    "print(\"=\"*70)\n",
    "print()\n",
    "\n",
    "model = xgb.train(\n",
    "    params=params,\n",
    "    dtrain=dtrain,\n",
    "    num_boost_round=1000,           # Maximum number of boosting rounds\n",
    "    evals=evals,\n",
    "    early_stopping_rounds=50,       # Stop if no improvement for 50 rounds\n",
    "    verbose_eval=50                 # Print metrics every 50 rounds\n",
    ")\n",
    "\n",
    "print()\n",
    "print(\"=\"*70)\n",
    "print(\"âœ… Model training completed!\")\n",
    "print(f\"ğŸ¯ Best iteration: {model.best_iteration}\")\n",
    "print(f\"ğŸ¯ Best validation AUC: {model.best_score:.4f}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2763bbea",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id='section6'></a>\n",
    "## ğŸ“ˆ Model Evaluation\n",
    "[Back to top](#top)\n",
    "\n",
    "<a id='section6-1'></a>\n",
    "### ğŸ“Š Performance Metrics\n",
    "\n",
    "Let's evaluate the model performance on our test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c51671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions\n",
    "y_pred_proba = model.predict(dtest)\n",
    "y_pred = (y_pred_proba >= 0.5).astype(int)\n",
    "\n",
    "# Calculate metrics\n",
    "auc = roc_auc_score(y_test, y_pred_proba)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Display results with beautiful formatting\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ”¥ XGBoost Model Performance ğŸ”¥\".center(70))\n",
    "print(\"=\"*70)\n",
    "print(f\"\\n{'Metric':<30} {'Score':>20}\")\n",
    "print(\"-\"*70)\n",
    "print(f\"{'ğŸ“Š ROC-AUC Score':<30} {auc:>20.4f}\")\n",
    "print(f\"{'ğŸ“Š Accuracy Score':<30} {acc:>20.4f}\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nğŸ“‹ Detailed Classification Report:\")\n",
    "print(\"=\"*70)\n",
    "print(classification_report(y_test, y_pred, target_names=['Not Paid Back', 'Paid Back']))\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fee7298",
   "metadata": {},
   "source": [
    "<a id='section6-2'></a>\n",
    "### ğŸ“Š Feature Importance\n",
    "\n",
    "Let's examine which features are most important for predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c901320a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importance\n",
    "importance_dict = model.get_score(importance_type='weight')\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': importance_dict.keys(),\n",
    "    'Importance': importance_dict.values()\n",
    "}).sort_values('Importance', ascending=False).head(15)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ† Top 15 Most Important Features\".center(70))\n",
    "print(\"=\"*70)\n",
    "print(f\"\\n{'Rank':<8} {'Feature':<35} {'Importance':>15}\")\n",
    "print(\"-\"*70)\n",
    "for idx, row in importance_df.iterrows():\n",
    "    rank = importance_df.index.get_loc(idx) + 1\n",
    "    print(f\"{rank:<8} {row['Feature']:<35} {row['Importance']:>15.0f}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d49662",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id='section7'></a>\n",
    "## ğŸ’¾ Save the Model\n",
    "[Back to top](#top)\n",
    "\n",
    "<div class=\"alert alert-block alert-success\" style=\"background-color: #d4edda; border-left: 5px solid #28a745; color: #2c3e50;\">\n",
    "<b style=\"color: #28a745;\">âœ… Model Persistence:</b><br>\n",
    "Save the trained model and preprocessing pipeline for future use and deployment.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893bf098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save_model(\"xgboost_loan_model.json\")\n",
    "print(\"âœ… Model saved as 'xgboost_loan_model.json'\")\n",
    "\n",
    "# Save preprocessing pipeline\n",
    "joblib.dump(preprocessing_pipeline, \"preprocessing_pipeline.pkl\")\n",
    "print(\"âœ… Preprocessing pipeline saved as 'preprocessing_pipeline.pkl'\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ’¾ Model artifacts saved successfully!\".center(70))\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40bb2f52",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id='section8'></a>\n",
    "## ğŸ¯ Generate Predictions for Test Set\n",
    "[Back to top](#top)\n",
    "\n",
    "Now let's load the test data and generate predictions for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31718c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data\n",
    "test_df = pd.read_csv(\"/kaggle/input/loan-repayment-prediction/test.csv\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"ğŸ“Š Test Dataset Loaded\".center(70))\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nğŸ“Š Test dataset shape: {test_df.shape}\")\n",
    "print(f\"ğŸ“Š Number of predictions to generate: {test_df.shape[0]:,}\")\n",
    "print(\"\\nğŸ” First 5 rows:\")\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1824401",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store IDs for submission\n",
    "test_ids = test_df['id'].copy()\n",
    "\n",
    "# Drop ID column for preprocessing\n",
    "test_features = test_df.drop(columns=['id'])\n",
    "\n",
    "# Apply preprocessing\n",
    "print(\"ğŸ”„ Preprocessing test data...\")\n",
    "test_preprocessed = preprocess_fn(test_features)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"âœ… Test data preprocessed successfully!\".center(70))\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nğŸ“Š Original shape: {test_features.shape}\")\n",
    "print(f\"ğŸ“Š Preprocessed shape: {test_preprocessed.shape}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1527aee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DMatrix for predictions\n",
    "dtest_submission = xgb.DMatrix(test_preprocessed)\n",
    "\n",
    "# Generate predictions (probabilities)\n",
    "print(\"ğŸ¯ Generating predictions...\")\n",
    "predictions = model.predict(dtest_submission)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"âœ… Predictions generated successfully!\".center(70))\n",
    "print(\"=\"*70)\n",
    "print(f\"\\n\udcca Prediction Statistics:\")\n",
    "print(f\"   Mean probability:  {predictions.mean():.4f}\")\n",
    "print(f\"   Std deviation:     {predictions.std():.4f}\")\n",
    "print(f\"   Min probability:   {predictions.min():.4f}\")\n",
    "print(f\"   Max probability:   {predictions.max():.4f}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21619ee",
   "metadata": {},
   "source": [
    "### ğŸ“¤ Create Submission File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba2dc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission dataframe\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_ids,\n",
    "    'loan_paid_back': predictions\n",
    "})\n",
    "\n",
    "# Save to CSV\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"âœ… Submission file created successfully!\".center(70))\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nğŸ“Š Submission file shape: {submission.shape}\")\n",
    "print(f\"ğŸ“Š Total predictions: {len(submission):,}\")\n",
    "print(\"\\nğŸ“‹ First 10 rows of submission:\")\n",
    "print(\"-\"*70)\n",
    "print(submission.head(10).to_string(index=False))\n",
    "print(\"\\nğŸ“‹ Last 10 rows of submission:\")\n",
    "print(\"-\"*70)\n",
    "print(submission.tail(10).to_string(index=False))\n",
    "print(\"=\"*70)\n",
    "print(\"\\nğŸ‰ Ready to submit to Kaggle! ğŸ‰\".center(70))\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24324e83",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id='section9'></a>\n",
    "## ğŸ‰ Summary\n",
    "[Back to top](#top)\n",
    "\n",
    "<h2 align=\"center\" style=\"color: #28a745;\">ğŸ† What We Accomplished</h2>\n",
    "\n",
    "<div class=\"alert alert-block alert-success\" style=\"background-color: #d4edda; border-left: 5px solid #28a745; color: #2c3e50;\">\n",
    "\n",
    "### âœ… Complete Pipeline Implementation:\n",
    "\n",
    "**1. Exploratory Data Analysis** ğŸ“Š\n",
    "- Analyzed dataset structure with 38+ features\n",
    "- Identified patterns in categorical and numerical features\n",
    "- Understood target variable distribution\n",
    "\n",
    "**2. Feature Engineering** ğŸ”§\n",
    "- Binary encoding for marital status\n",
    "- Split grade_subgrade into meaningful components\n",
    "- Created robust preprocessing functions\n",
    "\n",
    "**3. Data Preprocessing** âš™ï¸\n",
    "- Implemented One-Hot Encoding for categorical variables\n",
    "- Applied Standard Scaling for numerical features\n",
    "- Built reusable preprocessing pipelines\n",
    "\n",
    "**4. Model Training** ğŸš€\n",
    "- Used optimized hyperparameters from **Grid Search CV**\n",
    "- Trained XGBoost with early stopping\n",
    "- Leveraged GPU acceleration for faster training\n",
    "\n",
    "**5. Model Evaluation** ğŸ“ˆ\n",
    "- Assessed performance with multiple metrics\n",
    "- Analyzed feature importance\n",
    "- Validated on hold-out test set\n",
    "\n",
    "**6. Prediction Generation** ğŸ¯\n",
    "- Created submission file for Kaggle\n",
    "- Applied preprocessing to test data\n",
    "- Generated probability predictions\n",
    "\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ¯ Model Performance Highlights\n",
    "\n",
    "<div class=\"alert alert-block alert-info\" style=\"background-color: #e7f3ff; border-left: 5px solid #0066cc; color: #2c3e50;\">\n",
    "<b style=\"color: #0066cc;\">âš¡ Key Achievements:</b>\n",
    "<ul>\n",
    "<li><b>ROC-AUC Score:</b> High predictive power</li>\n",
    "<li><b>Training Strategy:</b> Grid Search CV with 3-fold cross-validation</li>\n",
    "<li><b>Regularization:</b> Applied to prevent overfitting</li>\n",
    "<li><b>Early Stopping:</b> Prevented overfitting during training</li>\n",
    "</ul>\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸš€ Future Improvements\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\" style=\"background-color: #fff3cd; border-left: 5px solid #ff9800; color: #2c3e50;\">\n",
    "<b style=\"color: #ff9800;\">ğŸ’¡ Potential Enhancements:</b>\n",
    "<ul>\n",
    "<li>ğŸ”„ <b>Ensemble Methods:</b> Try stacking or blending multiple models</li>\n",
    "<li>ğŸ¨ <b>Feature Engineering:</b> Create interaction features or polynomial features</li>\n",
    "<li>ğŸ¤– <b>Alternative Algorithms:</b> Experiment with LightGBM, CatBoost, or Neural Networks</li>\n",
    "<li>ğŸ¯ <b>Hyperparameter Tuning:</b> Use Bayesian Optimization or Optuna for more extensive search</li>\n",
    "<li>ğŸ“Š <b>Feature Selection:</b> Apply feature selection techniques to reduce dimensionality</li>\n",
    "<li>âš–ï¸ <b>Class Imbalance:</b> Explore SMOTE or other resampling techniques if needed</li>\n",
    "</ul>\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "<h3 align=\"center\" style=\"color: #1e3c72;\">ğŸ“š References & Resources</h3>\n",
    "\n",
    "<div align=\"center\" style=\"color: #2c3e50;\">\n",
    "\n",
    "- [XGBoost Documentation](https://xgboost.readthedocs.io/)\n",
    "- [Scikit-learn Pipeline Guide](https://scikit-learn.org/stable/modules/compose.html)\n",
    "- [Feature Engineering Best Practices](https://www.kaggle.com/learn/feature-engineering)\n",
    "\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "<h2 align=\"center\" style=\"color: #1e3c72;\">ğŸ™ Thank You!</h2>\n",
    "\n",
    "<div align=\"center\">\n",
    "<p style=\"font-size: 18px; color: #2c3e50;\">\n",
    "If you found this notebook helpful, please <b>upvote</b> ğŸ‘ and leave a comment!<br>\n",
    "Your feedback helps improve future iterations. ğŸ’¬\n",
    "</p>\n",
    "\n",
    "<img src=\"https://media.giphy.com/media/3o7abKhOpu0NwenH3O/giphy.gif\" width=\"200\">\n",
    "\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "<div align=\"center\">\n",
    "<i style=\"color: #666;\">Made with â¤ï¸ for the Kaggle Community</i>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
